Il problema di sistemi esperti e LCS è il rumore: _domare gli attrattori_

Bacino di attrattori -> la risposta corretta va verso gli attrattori
Bio-ispirate: come i neuroni umani se viene sovrastimolato (soglia superata), si attiva

#Vedi: Hebbian theory, grandmother neuron

Il riconoscimento di oggetti, persone e voci nel nostro cervello non fa attivare un solo neurone, ma diverse aree di esso.

I neuroni specchio si attivano quando vedo una persona che compie un'azione o che ha una reazione ad un "input". A questo punto mi si attivano processi come se fossi io in prima persona ad essere soggetto allo stimolo.

# McColluch e Pitts
Pionieri delle reti neurali: 1 solo neurone a 2 livelli. Neurone booleano:
- 0, 1
- -1, 1

Visualmente 
![[neuron.webp]]

Il neurone di McColluch-Pitts può essere scomposto in due funzioni distinte:
- la funzione di **aggregazione** _g_ che definisce come gestire gli ingressi, solitamente è un semplice prodotto vettoriale ingressi per pesi $x \cdot w$
- la funzione di **attivazione** _f_ che definisce le condizioni di stimolazione del neurone, tipicamente è un gradino di **Heaviside** (1 soprasoglia, 0 sottosoglia)

La funzione di attivazione del neurone può essere una qualsivoglia funzione, non necessariamente booleana (anche a valori reali, ad esempio per restituire in uscita una probabilità). Quelle più utilizzate sono:
- lineare o lineare clampata (saturata)
- sigmoidale o logistica
- booleana (Heaviside, con o senza bias)

Ad ogni neurone arrivano in ingresso diversi input, con un peso associato: $$ I = w_1 x_1 + w_2 x_2 + \dots + w_n x_n $$
Questo modello permette di costruire una porta logica per ogni neurone:
- OR -> ogni ingresso ha peso 1, soglia 0.5
- AND -> ogni ingresso ha peso 1, soglia 1.5
- NAND -> ogni ingreso ha peso -1, soglia -1.5
- AND NOT -> pesi 1, -1, soglia 0.5
- XOR (attiva se input diversi) -> serve uno stato aggiuntivo (percettroni) -> Due layer: AND e OR perchè le uscite dello XOR non sono linearmente separabili

In tutti questi esempi abbiamo usato soglie e pesi ben definiti. Questo è normalmente lo scopo della fase di **apprendimento** di una rete neurale: trovare soglie (tipicamente si lavora a soglia nulla) e pesi che facciano funzionare la rete come ci si aspetta.

# Modello di Hopfield
Fa uso dei neuroni appena descritti.

Si ispira agli spin dei campi magnetici. Ognuno degli N nodi è booleano a soglia.
Tutti i nodi sono connessi con tutti. Per ogni nodo esiste una sinapsi entrante e una uscente verso ogni altro nodo.

I pesi sinaptici sono: $w_{ij} \in \mathbb{R} \space \forall i, j = 1, ..., N \space i \neq j$

I self-loop hanno tutti peso 0, dato che autoinibizione e autostimolazione non sono consentite.

Ogni neurone ha soglia $\theta_i \space \forall i = 1, ..., N$

L'input netto dell'i-esimo neurone, dato un vettore di input $X(t)$ è $I_i(X(t)) = \sum_k w_i^k x^k(t)$ con k che scorre tutti gli archi entranti, pari a N (dato che vengono considerati i self-loop, anche se con peso 0).

## Inferenza
Durante la fase di inferenza succede che ogni nodo valuta il suo input netto e, se soprasoglia, aggiorna il suo stato a 1; se sottosoglia emette 0; rimane invariato se $I = \theta$

Posso memorizzare tutto in $X$ dato che ogni nodo è sia un'ingresso che un'uscita.

![[HebbianWeight.svg]]

## Addestramento
Per l'addestramento di una NN di Hopfield è necessario aggiornare $N(N-1)$ pesi (1 per sinapsi). Per determinare la convergenza dell'addestramento si ispira allo spin dei materiali ferromagnetici (stabili) e anti-ferromagnetici (non stabili).

Questa è una funzione di **Lyapunov**, ovvero una funzione che cala sempre (energia non crescente). L'energia totale del sistema cala finchè non raggiunge un attrattore. $$E(X(t+1)) \leq E(X(t))$$
> Conseguenza: durante la fase di inferenza una rete di Hopfield arriva sempre ad un punto di stabilità

## Funzione energia
$$E(X) = \frac{1}{2}\sum_{i,j=1,i \neq j}^Nw_{ij}x_ix_j + \sum_{i=1}^N \theta_ix_i$$
Questa è la funzione di energia del sistema, dove $X$ è un input. La prima parte ricorda la formula dell'energia cinetica ($\frac{1}{2}mv^2$):
- $\frac{1}{2}$ costante
- $w$ peso/massa dell'ingresso
- $x^2$ valori agli estremi della sinapsi al quadrato

La seconda parte della funzione di energia è un offset è può essere interpretato come l'energia di attivazione della rete.

### Dimostrazione: E è monotona non crescente
**Ipotesi**:
1. Aggiornamento asincrono dei neuroni
2. Matrice dei pesi $W$ simmetrica -> $W_{ij} = W_{ji}$
3. Sulla diagonale principale della matrice dei pesi abbiamo 0 -> il contributo dei self-loop è nullo

#Nota: ad ogni passo cambia un solo neurone con una strategia di aggiornamento asincrona.

**Tesi**:
- $E(X(t+1)) \leq E(X(t))$ dove X è il vettore dello stato corrente dei nodi, contenente N elementi, pari al numero N di neuroni (ricorda che ogni nodo è si input che output nel modello di Hopfield)

**Dimostrazione**:
1. Riscriviamo la tesi in modo analogo portando $E(X(t))$ al primo membro della disequazione: $\Delta E(t) = E(X(t+1)) - E(X(t)) \leq 0$
2. Dall'HP1 al tempo $t$ viene aggiornato un solo neurone, che chiameremo $k$: $\Delta X_k(t)=X_k(t+1)-X_k(t)$ è la sua variazione
3. La variazione di energia ottenuta modificando il nodo $k$ è: $\Delta E(t) = -\frac{1}{2} \sum_{i, j = 1}^N w_{ij} [X_i(t+1)X_j(t+1)-X_i(t)X_j(t)](\delta_{ik} + \delta_{jk}) + \theta_k\Delta X_k(t)$, ovvero contribuiscono i soli archi connessi a k (chiaramente moltiplicati per i valori dei nodi agli estremi), grazie a $(\delta_{ik} + \delta_{jk})$ che fa uso del delta di Kronecker per la selezione
4. Spezzo la sommatoria: $\Delta E(t) = -\frac{1}{2} [\sum_{i=1}^N w_{ik} [X_i(t+1)X_k(t+1)-X_i(t)X_k(t)] + \sum_{j=1}^N w_{kj} [X_k(t+1)X_j(t+1)-X_k(t)X_j(t)]] + \theta_k\Delta X_k(t)$
5. La riassemblo con indice singolo e uso HP2 (simmetria dei pesi): $\Delta E(t) = -\frac{1}{2} \sum_{i=1}^N 2w_{ik} [X_i(t+1)X_k(t+1)-X_i(t)X_k(t)] + \theta_k\Delta X_k(t)$
6. Semplifico il 2: $\Delta E(t) = -\sum_{i=1}^N w_{ik} [X_i(t+1)X_k(t+1)-X_i(t)X_k(t)] + \theta_k\Delta X_k(t)$
7. Da HP1 abbiamo che $X_i(t+1) = X_i(t)$ se $i \neq k$, ovvero non c'è variazione di stato per tutti i neuroni che non siano quello che viene aggiornato correntemente. Quindi: $\Delta E(t) = - \sum_{i=1}^N w_{ik} X_i(t)[X_k(t+1)-X_k(t)] + \theta_k\Delta X_k(t)$. La sommatoria non proibisce che $i$ sia uguale a $k$, ma in questo caso il contributo sarà nullo a causa di $w_{kk} = 0$ da HP3
8. La variazione del nodo $k$ è indipendente dall'indice $i$: $\Delta E(t) = - \Delta X_k(t) \sum_{i=1}^N w_{ik} X_i(t) + \theta_k\Delta X_k(t)$
9. Raccolgo $-\Delta X_k(t)$: $\Delta E(t) = - \Delta X_k(t) [\sum_{i=1}^N w_{ik} X_i(t) - \theta_k]$
10. La sommatoria è l'input netto del nodo $k$: $\Delta E(t) = - \Delta X_k(t)[I_k(X(t)) - \theta_k]$
11. Osservazioni finali che ci portano a dire che $\Delta E(t) \leq 0$
	1. $\Delta X_k(t)$ e $I_k(X(t))$ sono strettamente collegati
	2. Non bisogna fasi trarre in inganno dal fatto che $\Delta X_k(t)$ è parametrizzato solo su $t$
	3. Infatti $\Delta X_k(t) = X_k(t+1) - X_k(t)$
	4. Ma $X_k(t+1)$ è determinato proprio sulla base di $I_k(X(t)) - \theta_k$ funzione di attivazione:
		- se $I_k(X(t))$ è sottosoglia $I_k(X(t)) - \theta_k$ è negativo, quindi $X(t+1)$ è sicuramente 0.
			- Se $X(t)$ era 0 -> $\Delta X_k(t) = 0$ e $\Delta E(t) = 0$
			- Se $X(t)$ era 1 -> $\Delta X_k(t) = -1$ e $\Delta E(t) < 0$ (tre fattori negativi)
		- se $I_k(X(t))$ è soprasoglia $I_k(X(t)) - \theta_k$ è positivo, quindi $X(t+1)$ è sicuramente 1.
			- Se $X(t)$ era 0 -> $\Delta X_k(t) = 1$ e $\Delta E(t) < 0$ (un fattore negativo, due positivi)
			- Se $X(t)$ era 1 -> $\Delta X_k(t) = 0$ e $\Delta E(t) = 0$ (tre fattori negativi)

# Apprendimento hebbiano
Si adatta particolarmente al modello di Hopfield.

Da Donald Hebb (1949), neurologo. Quando un assone di una cellula eccita ripetutamente un'altra cellula, allora si verifica un processo di crescita e rinforzo della sinapsi.

Allo stesso modo se due neuroni si attivano in sincrono, allora il loro legame va rafforzato.

#Vedi: esperimento di Pavlov con i cani -> riflesso incondizionato: crea legame tra l'area dell'udito e quella della digestione. Aumenta fisicamente lo spessore delle sinapsi.

Se sono in **antifase** uno si spegne e l'altro si accende, se sono in fase (entrambi accersi o spenti) si rafforzano.

Insegnando un pattern $A = (a_1 \dots a_N)$ in ingresso, le sinapsi dei neuroni nello stesso stato aumentano di valore. Una soluzione potrebbe essere $\Delta w_{ij} = (2A_i - 1) (2A_j - 1)$. Infatti:

| $A_i$ | $A_j$ | $\Delta w$ |
|---|---|---|
|0|0|1|
|0|1|-1|
|1|0|-1|
|1|1|1|

Si può derivare una funzione analoga a partire dalla traduzione da logica booleana ad equazioni reali dello XOR:
1. XOR(a, b) = (a' + b) (a + b') con sintesi PS (detta anche CNF)
2. Equivale al sistema di:
	1. a + (1-b) > 0
	2. (1-a) + b > 0
3. Noto che 1 e 2 moltiplicati danno 1 se concordi, 0 altrimenti
4. Moltiplico per 2 e sottraggo 1 per scalare linearmente su \[-1, 1\]: $2[a+(1-b)][(1-a)+b]-1$
5. Sviluppo e ottengo $4ab-2a^2-2b^2+1$
6. Considerando che $a$ e $b$ possono valere 0 o 1 i quadrati sono superflui
7. Ottengo la formula di Hebb

Allenando una NN di Hopfield a riconoscere un pattern A, ho automaticamente un attrattore anche per A'. In più lo un ingresso omogeneo nullo (esempio vettore nullo X) è un attrattore naturale in quanto l'ingresso netto pareggia la soglia, ammesso che i neuroni siano a soglia nulla come accade tipicamente.

## Apprendimento di m pattern
Dati m pattern $A^1, ..., A^M$ da insegnare alla rete, il $\Delta w$ da applicare ad una sinapsi è la somma dei contributi di tutti i pattern (di tutti i fronti, le somiglianze/differenze di spin).

$$\Delta w_{ij} = (2A_i^m-1)(2A^m_j-1)$$
con m che scorre sugli M pattern e i, j che scorrono sugli N neuroni.

## Dimostrazione: la reti di Hopfield lavora per sovrapposizione
#Nota:  Date due stringhe di bit X e Y le differenze di X con Y e le differenze di X' con Y, se sommate, restituiscono tutti i bit accesi di Y. In logica booleana: $X \cdot Y + \bar X \cdot Y = (X + \bar X) \cdot Y = Y$

Useremo la notazione $Q(X, Y)$ per identificare le differenze tra le due stringhe di bit.

#Nota: $2a-1 = a - \bar a$ se $a$ è booleano

1. $I_i(X(t)) = \sum_{i \neq j, j = 1}^N W_{ij}X_j$ l'ingresso netto dell'i-esimo neurone è il prodotto vettoriale tra W (vettore dei pesi) e X (vettore degli ingressi)
2. $I_i(X(t)) = \sum_{i \neq j, j = 1}^N \sum_m (2A_i^m-1)(2A_j^m-1)X_j$ dall'apprendimento hebbiano
3. $I_i(X(t)) = \sum_m\sum_{i \neq j, j = 1}^N  (2A_i^m-1)(2A_j^m-1)X_j$ dalle proprietà delle sommatorie
4. $I_i(X(t)) = \sum_m (2A_i^m-1) \sum_{i \neq j, j = 1}^N  (2A_j^m-1)X_j$ dato che il fattore è indipendente dall'indice j
5. $I_i(X(t)) = \sum_m (2A_i^m-1) \sum_{i \neq j, j = 1}^N  (A_j^m - \bar A_j^m)X_j$ dalla seconda nota
6. $I_i(X(t)) = \sum_m (2A_i^m-1) \sum_{i \neq j, j = 1}^N  (A_j^m X_j - \bar A_j^m X_j)$ sviluppando il prodotto. Si notano due sovrapposizioni parziali (come le sovrapposizioni Q definite sopra a meno degli elementi con j=i)
7. $I_i(X(t)) = \sum_m (2A_i^m-1) [Q(A^m, X) - Q(\bar A^m, X)] - X_i \sum_m (A^m_i - \bar A^m_i)^2$ tolgo il contributo della sommatoria qundo i = j, ovvero $X_i(A_i^m - \bar A_i^m)$. Il quadrato rende sempre positiva la quantità al suo interno, che può essere -1 o 1.
8. Quindi possiamo scrivere $I_i(X(t)) = \sum_m (2A_i^m-1) [Q(A^m, X) - Q(\bar A^m, X)] - M X_i$
Considerazioni:
- dal secondo addendo interno alle parentesi quadre si vede che le reti di Hopfield memorizzano anche i complementare di un pattern.
- Il primo fattore detta il segno: con uno zero (sottosoglia) abbiamo un -1, con un 1 (soprasoglia) abbiamo un 1.
- poi viene tolto un contributo che dipende dal numero di pattern da imparare.

# Note sul modello di Hopfield con apprendimento hebbiano
La rete di Hopfield con apprendimento hebbiano si configura dopotutto come una gara di sovrapposizione. Quella a cui si avvicina di più l'ingresso (idealmente sporcato dal rumore) funge da bacino di attrazione. È una gara di sovrapposizioni.

Pattern simili danno vita a fenomeni di **interferenza**.

#Stat: dati M pattern casuali e scorrelati con $P\{A_i^m = 0\} = P\{A_i^m = 0\} = \frac{1}{2}$ per $m$ che itera su $M$ e $i$ che itera su $N$ => $M_{max} \approx 0.14 N$ Il numero massimo di pattern apprendibili è proporzionale al 15% del numero di nodi.

Nel modello di Hopfield la forma corretta, per esempio, di una lettera può essere dedotta da lettere scritte male. Grazie alla messa in and (**sovrapposizione**) delle uscite dei vari neuroni si ottiene la resistenza al rumore. Questa operazione di generalizzazione è l'estrazione di archetipi: inferenza della forma corretta di un pattern a partire da K versioni distorte dello stesso.

# Percettroni
I percettroni sono conformi al modello di neurone di McCulloch-Pitts: hanno una funzione di aggregazione e una di attivazione.
La funzione di aggregazione è solitamente lineare (combinazione lineare degli ingressi, pesati): $I = \sum_{i=1}^n w_i x_i = w_1 x_1 + w_2 x_2 + ... + w_n x_n$

La funzione di attivazione è solitamente una funzione di **Heaviside** (il gradino di Heaviside ha per definizione una soglia nulla). Per spostare la soglia basta fare $H(I - \theta)$

L'ingresso della funzione di attivazione è quindi $I - \theta = w_1 x_1 + w_2 x_2 + ... + w_n x_n - \theta$, ovvero una funzione affine, che rappresenta un **iperpiano**. In due dimensioni un piano, in una una retta.

Addestrare un percettrone significa trovare pesi e soglie che permettano una buona inferenza/generalizzazione/classificazione. Su un singolo percettrone significa quindi trovare i coefficienti (angolari e termine noto) del semipiano in modo che divida correttamente il set in ingresso (un lattice di punti). Solitamente si parte con coefficienti casuali.

Il semipiano dà vita a due regioni; in base alla regione in cui si trova l'ingresso l'uscita del percettrone può essere 0 o 1.

Per "ripulire" l'input di $H$ solitamente si aggiunge un ingresso fittizio con valore bloccato a $\theta$ e peso $-1$.

Uscita: $y = H(\sum_k w_k x_k)$

## Percettroni ad 1 livello
### Apprendimento
Conosciuti i seguenti elementi:
- la risposta desiderata della rete $y_d$
- $\epsilon$ scalare piccolo
- $x$ vettore di ingresso
- $w$ vettore di pesi

Posso allenare il percettrone correggendo i pesi come segue:
- calcolo $y = H(x \cdot w)$
- ricalcolo i pesi
	- se $y = y_d$ -> $w(k+1) = w(k)$, i pesi sono invariati
	- se $y > y_d$ -> $w(k+1) = w(k) - \epsilon x$, la risposta è superiore a quella desiderata
	- se $y < y_d$ -> $w(k+1) = w(k) + \epsilon x$, la risposta è inferiore a quella desiderata

### Teorema del percettrone
Valido per percettroni semplici (N ingressi, N pesi, 1 uscita, 1 layer) booleani.

**Ipotesi**:
1. la funzione di attivazione è una funzione lineare a soglia

**Tesi:** la regola di apprendimento locale del percettrone convergerà a pesi che la realizzano in un numero finito di passi.

Idea: usare $\epsilon \approx \frac{1}{k}$ inversamente proporzionale al passo

![[TassoDiApprendimento.png]]
$\epsilon$ è chiamato tasso di apprendimento:
- un tasso di apprendimento basso permette una regolazione fine, ma lenta
- un tasso di apprendimento alto permette una regolazione veloce, ma grossolana

È buona norma dividere il set di dati in:
- training set per allenare la rete
- test set per verificare la bontà dell'allenamento su casi mai visti prima

### Percettroni continui
#### Funzioni di trasferimento
Vanno a sostituire quella che prima era il gradino di Heaviside.

Le funzioni di attivazione o trasferimento, dette anche *squashing functions*, sono quasi sempre monotone non decrescenti. Le più utilizzate sono
- $f(x) = \frac{A}{1+b^{-kx}}$
- $f(x)=A \frac{e^{kx}-e^{-kx}}{e^{kx}+e^{-kx}}$

#### Delta rule
La delta rule è l'equivalente del teorema del percettrone nel caso continuo. Si applica a single layer neural networks (feed forward). Utilizza la discesa del gradiente per fare apprendere la rete.

Obiettivo: si vuole minimizzare l'errore $E$  ->  ottimizzare i pesi in modo tale da minimizzare l'errore.

$$E_i = (y_i - y_i^d)^2$$
$$E=\sum_i E_i$$

Oppure pensando $y$ e $y^d$ in termini vettoriali: $E = (\| y - y^d \|_2)^2$

Obiettivo: $min E$, possibilmente $E=0$. Ad ogni passo della delta rule: $\Delta w$ tale che $\Delta E \leq 0$

Se w scalare:
- se E(w) crescente, allora diminuisco w
- se E(w) decrescente, allora aumento w

$$\Delta w = \epsilon(\frac{dE}{dw})$$
Con w vettoriale: $\Delta w = -\epsilon \nabla E(w)$, il gradiente sarà un vettore di derivate parziali

#Nota: nel mondo reale non esiste un solo minimo globale che rappresenta l'ottimo, poiché con tutte le possibilità la funzione errore da minimizzare non è lineare. Questo significa che l'ottimizzazione, raggiunto un minimo locale, non ne potrà più uscire. Nella fase di apprendimento può essere quindi necessario ripartire da zero, con punto iniziale casuale (vettore w)

Il percettrone semplice ha un rapporto $\frac{f separabili}{f booleane} \rightarrow 0$, è quindi necessario abbandonarlo.

## Multi-layer perceptrons (MLP)
I percettroni a più livelli possono essere astratti in:
1. layer di ingresso
2. layer nascosti (intermedi)
3. layer di uscita

Si pone ora il problema di determinare i pesi intermedi durante la fase di allenamento.

Una delle tecniche utilizzate è la backpropagation: catene di derivate (gradienti) vengono usate per determinare l'influenza dei pesi dei vari strati a ritroso (da OUT a IN) sull'errore.

# Over and under fitting
>**Overfitting**: problematica delle NN tale per cui la rete ha imparato le **idiosincrasie** e rumore del training set. Si perde l'abilità di generalizzazione. Corrisponde ad un iperpiano molto precisio nella divisione del training set.

>**Underfitting**: fenomeno per cui la rete è dotata di grande generalizzazione, ma è troppo poco precisa nei risultati che restituisce.

Nel primo caso si è minimizzato così tanto l'errore che gli esempi del dataset sono intrinseci nella memoria del sistema. Nel secondo caso si è ridotto troppo poco l'errore.

Come sapere quando fermarsi? solitamente ci si ferma quando errore sul training set continua a calare, mentre l'errore sul test set inizia ad aumentare.

